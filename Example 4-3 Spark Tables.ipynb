{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Tables\n",
    "\n",
    "This notebook shows how to use Spark Catalog Interface API to query databases, tables, and columns.\n",
    "\n",
    "A full list of documented methods is available [here](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Spark Tables\").enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_flights_file = \"/home/karthik/SparkCourse/pyspark notebooks/data/departuredelays.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a database and a table\n",
    "spark.sql(\"\"\"DROP DATABASE IF EXISTS sparklearn_db\"\"\")\n",
    "spark.sql(\"\"\"CREATE DATABASE IF NOT EXISTS sparklearn_db\"\"\")\n",
    "spark.sql(\"\"\"USE sparklearn_db\"\"\")\n",
    "spark.sql(\"\"\"CREATE TABLE us_delays_flights_tbl(date STRING, delay INT, distance INT, origin STRING, destination STRING)\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------------+-----------+\n",
      "|database     |tableName            |isTemporary|\n",
      "+-------------+---------------------+-----------+\n",
      "|sparklearn_db|us_delays_flights_tbl|false      |\n",
      "+-------------+---------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SHOW TABLES\"\"\").show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read our US Flights table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(us_flights_file, header=True,schema=\"date STRING, delay INT, distance INT, origin STRING, destination STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+------+-----------+\n",
      "|date    |delay|distance|origin|destination|\n",
      "+--------+-----+--------+------+-----------+\n",
      "|01011245|6    |602     |ABE   |ATL        |\n",
      "|01020600|-8   |369     |ABE   |DTW        |\n",
      "|01021245|-2   |602     |ABE   |ATL        |\n",
      "|01020605|-4   |602     |ABE   |ATL        |\n",
      "|01031245|-4   |602     |ABE   |ATL        |\n",
      "+--------+-----+--------+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save into our table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").saveAsTable(\"us_delays_flights_tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CACHE TABLE us_delays_flights_tbl\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the table is cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.isCached(\"us_delays_flights_tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display tables within a Database\n",
    "\n",
    "Note that the table is MANGED by Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='us_delays_flights_tbl', database='sparklearn_db', description=None, tableType='MANAGED', isTemporary=False)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables(\"sparklearn_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Columns for a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Column(name='date', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='delay', description=None, dataType='int', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='distance', description=None, dataType='int', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='origin', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='destination', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listColumns(\"us_delays_flights_tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Unmanaged Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"USE sparklearn_db\")\n",
    "spark.sql(\"\"\"CREATE TABLE us_delays_flights_tbl_um(date STRING, delay INT, distance INT, origin STRING, destination STRING)\n",
    "USING csv\n",
    "OPTIONS(path \"/home/karthik/SparkCourse/pyspark notebooks/data/departuredelays.csv\", header=\"True\")\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Tables\n",
    "\n",
    "**Note**: The table type here that tableType='EXTERNAL', which indicates it's unmanaged by Spark, whereas above the tableType='MANAGED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='us_delays_flights_tbl', database='sparklearn_db', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='us_delays_flights_tbl_um', database='sparklearn_db', description=None, tableType='EXTERNAL', isTemporary=False)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables(\"sparklearn_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Columns for a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Column(name='date', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='delay', description=None, dataType='int', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='distance', description=None, dataType='int', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='origin', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='destination', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listColumns(\"us_delays_flights_tbl_um\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
