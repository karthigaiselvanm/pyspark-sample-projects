{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4.1\n",
    "\n",
    "This notebook shows Example 4.1 from the book showing how to use SQL on a US Flights Dataset dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.appName('Example 4.1').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a UDF to convert the date format into a legible format.\n",
    "\n",
    "*Note*: the date is a string with year missing, so it might be difficult to do any queries using SQL `year()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'02/19 09:25'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_date_format_udf(date_str):\n",
    "    l = [char for char in date_str]\n",
    "    return \"\".join(l[0:2]) + \"/\" + \"\".join(l[2:4])+ \" \" + \"\".join(l[4:6]) + \":\" + \"\".join(l[6:])\n",
    "\n",
    "to_date_format_udf(\"02190925\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.to_date_format_udf(date_str)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(\"to_date_format_udf\",to_date_format_udf,StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read our US departure flight data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "     .format(\"csv\")\n",
    "     .option(\"header\",\"true\")\n",
    "     .schema(\"date STRING,delay INT, distance INT, origin STRING, destination STRING\")\n",
    "     .option(\"path\",\"/home/karthik/SparkCourse/pyspark notebooks/data/departuredelays.csv\")\n",
    "     .load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+------+-----------+\n",
      "|date    |delay|distance|origin|destination|\n",
      "+--------+-----+--------+------+-----------+\n",
      "|01011245|6    |602     |ABE   |ATL        |\n",
      "|01020600|-8   |369     |ABE   |DTW        |\n",
      "|01021245|-2   |602     |ABE   |ATL        |\n",
      "|01020605|-4   |602     |ABE   |ATL        |\n",
      "|01031245|-4   |602     |ABE   |ATL        |\n",
      "|01030605|0    |602     |ABE   |ATL        |\n",
      "|01041243|10   |602     |ABE   |ATL        |\n",
      "|01040605|28   |602     |ABE   |ATL        |\n",
      "|01051245|88   |602     |ABE   |ATL        |\n",
      "|01050605|9    |602     |ABE   |ATL        |\n",
      "+--------+-----+--------+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- delay: integer (nullable = true)\n",
      " |-- distance: integer (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- destination: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1391578"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|date    |date_formatted|\n",
      "+--------+--------------+\n",
      "|01011245|01/01 12:45   |\n",
      "|01020600|01/02 06:00   |\n",
      "|01021245|01/02 12:45   |\n",
      "|01020605|01/02 06:05   |\n",
      "|01031245|01/03 12:45   |\n",
      "|01030605|01/03 06:05   |\n",
      "|01041243|01/04 12:43   |\n",
      "|01040605|01/04 06:05   |\n",
      "|01051245|01/05 12:45   |\n",
      "|01050605|01/05 06:05   |\n",
      "+--------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"date\",expr(\"to_date_format_udf(date) as date_formatted\")).show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a temporary view to which we can issue SQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"us_flight_delays_tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cache Table so queries are expedient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CACHE TABLE us_flight_delays_tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all `date` to `date_fm` so it's more eligible\n",
    "\n",
    "Note: we are using UDF to convert it on the fly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+------+-----------+--------+------------------------+\n",
      "|date    |delay|distance|origin|destination|date    |to_date_format_udf(date)|\n",
      "+--------+-----+--------+------+-----------+--------+------------------------+\n",
      "|01011245|6    |602     |ABE   |ATL        |01011245|01/01 12:45             |\n",
      "|01020600|-8   |369     |ABE   |DTW        |01020600|01/02 06:00             |\n",
      "|01021245|-2   |602     |ABE   |ATL        |01021245|01/02 12:45             |\n",
      "|01020605|-4   |602     |ABE   |ATL        |01020605|01/02 06:05             |\n",
      "|01031245|-4   |602     |ABE   |ATL        |01031245|01/03 12:45             |\n",
      "|01030605|0    |602     |ABE   |ATL        |01030605|01/03 06:05             |\n",
      "|01041243|10   |602     |ABE   |ATL        |01041243|01/04 12:43             |\n",
      "|01040605|28   |602     |ABE   |ATL        |01040605|01/04 06:05             |\n",
      "|01051245|88   |602     |ABE   |ATL        |01051245|01/05 12:45             |\n",
      "|01050605|9    |602     |ABE   |ATL        |01050605|01/05 06:05             |\n",
      "+--------+-----+--------+------+-----------+--------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT *,date,to_date_format_udf(date) FROM us_flight_delays_tbl LIMIT 10\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 1391578|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(*) FROM us_flight_delays_tbl\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1:\n",
    "\n",
    " Find out all flights whose distance between origin and destination is greater than 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+--------+\n",
      "|origin|destination|distance|\n",
      "+------+-----------+--------+\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "+------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT origin\n",
    "                  , destination\n",
    "                  , distance \n",
    "               FROM us_flight_delays_tbl \n",
    "              WHERE distance > 1000 \n",
    "            ORDER BY distance DESC\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the same results as above using DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+--------+\n",
      "|origin|destination|distance|\n",
      "+------+-----------+--------+\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "|HNL   |JFK        |4330    |\n",
      "+------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df\n",
    " .select(\"origin\",\"destination\",\"distance\")\n",
    " .filter(col(\"distance\")>1000)\n",
    " .orderBy(\"distance\", ascending=False)\n",
    " .show(truncate=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2:\n",
    "\n",
    " Find out all flights with 2 hour delays between San Francisco and Chicago  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-----+\n",
      "|origin|destination|delay|\n",
      "+------+-----------+-----+\n",
      "|   SFO|        ORD| 1638|\n",
      "|   SFO|        ORD|  396|\n",
      "|   SFO|        ORD|  326|\n",
      "|   SFO|        ORD|  320|\n",
      "|   SFO|        ORD|  297|\n",
      "|   SFO|        ORD|  296|\n",
      "|   SFO|        ORD|  279|\n",
      "|   SFO|        ORD|  274|\n",
      "|   SFO|        ORD|  266|\n",
      "|   SFO|        ORD|  258|\n",
      "|   SFO|        ORD|  225|\n",
      "|   SFO|        ORD|  223|\n",
      "|   SFO|        ORD|  215|\n",
      "|   SFO|        ORD|  203|\n",
      "|   SFO|        ORD|  197|\n",
      "|   SFO|        ORD|  196|\n",
      "|   SFO|        ORD|  193|\n",
      "|   SFO|        ORD|  190|\n",
      "|   SFO|        ORD|  189|\n",
      "|   SFO|        ORD|  184|\n",
      "+------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT origin\n",
    "     , destination\n",
    "     , delay\n",
    "  FROM us_flight_delays_tbl\n",
    " WHERE origin = 'SFO'\n",
    "   AND destination = 'ORD'\n",
    "   AND delay > 120\n",
    " ORDER BY delay DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame Equivalent Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-----+\n",
      "|origin|destination|delay|\n",
      "+------+-----------+-----+\n",
      "|   SFO|        ORD| 1638|\n",
      "|   SFO|        ORD|  396|\n",
      "|   SFO|        ORD|  326|\n",
      "|   SFO|        ORD|  320|\n",
      "|   SFO|        ORD|  297|\n",
      "|   SFO|        ORD|  296|\n",
      "|   SFO|        ORD|  279|\n",
      "|   SFO|        ORD|  274|\n",
      "|   SFO|        ORD|  266|\n",
      "|   SFO|        ORD|  258|\n",
      "|   SFO|        ORD|  225|\n",
      "|   SFO|        ORD|  223|\n",
      "|   SFO|        ORD|  215|\n",
      "|   SFO|        ORD|  203|\n",
      "|   SFO|        ORD|  197|\n",
      "|   SFO|        ORD|  196|\n",
      "|   SFO|        ORD|  193|\n",
      "|   SFO|        ORD|  190|\n",
      "|   SFO|        ORD|  189|\n",
      "|   SFO|        ORD|  184|\n",
      "+------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df\n",
    " .select(\"origin\",\"destination\",\"delay\")\n",
    " .filter(expr(\"origin == 'SFO' AND destination = 'ORD' AND delay > 120\"))\n",
    " .orderBy(\"delay\",ascending=False)\n",
    " .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3:\n",
    "\n",
    "A more complicated query in SQL, let's label all US flights originating from airports with _high_, _medium_, _low_, _no delays_, regardless of destinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-----+-------------+\n",
      "|origin|destination|delay|flight_delays|\n",
      "+------+-----------+-----+-------------+\n",
      "|   ABE|        ATL|  333|  Long Delays|\n",
      "|   ABE|        ATL|  305|  Long Delays|\n",
      "|   ABE|        ATL|  275|  Long Delays|\n",
      "|   ABE|        ATL|  257|  Long Delays|\n",
      "|   ABE|        ATL|  247|  Long Delays|\n",
      "|   ABE|        DTW|  247|  Long Delays|\n",
      "|   ABE|        ORD|  219|  Long Delays|\n",
      "|   ABE|        ATL|  211|  Long Delays|\n",
      "|   ABE|        DTW|  197|  Long Delays|\n",
      "|   ABE|        ORD|  192|  Long Delays|\n",
      "|   ABE|        ATL|  180|  Long Delays|\n",
      "|   ABE|        DTW|  173|  Long Delays|\n",
      "|   ABE|        ATL|  165|  Long Delays|\n",
      "|   ABE|        ATL|  159|  Long Delays|\n",
      "|   ABE|        ORD|  159|  Long Delays|\n",
      "|   ABE|        ATL|  158|  Long Delays|\n",
      "|   ABE|        DTW|  151|  Long Delays|\n",
      "|   ABE|        ATL|  127|  Long Delays|\n",
      "|   ABE|        DTW|  121|  Long Delays|\n",
      "|   ABE|        DTW|  118| Short Delays|\n",
      "+------+-----------+-----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT origin\n",
    "     , destination\n",
    "     , delay\n",
    "     , CASE WHEN delay >= 360 THEN 'Very Long Delays'\n",
    "            WHEN delay >= 120 AND delay < 360 THEN 'Long Delays'\n",
    "            WHEN delay >= 60 AND delay < 120 THEN 'Short Delays'\n",
    "            WHEN delay > 0 AND delay < 60 THEN 'Very Short Delays'\n",
    "            ELSE 'Early' END AS flight_delays\n",
    "  FROM us_flight_delays_tbl\n",
    " ORDER BY origin, delay DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalent DataFrame Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-----+-------------+\n",
      "|origin|destination|delay|flight_delays|\n",
      "+------+-----------+-----+-------------+\n",
      "|   ABE|        ATL|  333|  Long Delays|\n",
      "|   ABE|        ATL|  305|  Long Delays|\n",
      "|   ABE|        ATL|  275|  Long Delays|\n",
      "|   ABE|        ATL|  257|  Long Delays|\n",
      "|   ABE|        ATL|  247|  Long Delays|\n",
      "|   ABE|        DTW|  247|  Long Delays|\n",
      "|   ABE|        ORD|  219|  Long Delays|\n",
      "|   ABE|        ATL|  211|  Long Delays|\n",
      "|   ABE|        DTW|  197|  Long Delays|\n",
      "|   ABE|        ORD|  192|  Long Delays|\n",
      "|   ABE|        ATL|  180|  Long Delays|\n",
      "|   ABE|        DTW|  173|  Long Delays|\n",
      "|   ABE|        ATL|  165|  Long Delays|\n",
      "|   ABE|        ATL|  159|  Long Delays|\n",
      "|   ABE|        ORD|  159|  Long Delays|\n",
      "|   ABE|        ATL|  158|  Long Delays|\n",
      "|   ABE|        DTW|  151|  Long Delays|\n",
      "|   ABE|        ATL|  127|  Long Delays|\n",
      "|   ABE|        DTW|  121|  Long Delays|\n",
      "|   ABE|        DTW|  118| Short Delays|\n",
      "+------+-----------+-----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df\n",
    ".select(\"origin\",\"destination\",\"delay\")\n",
    ".withColumn(\"flight_delays\",\n",
    "            expr(\"CASE WHEN delay >= 360 THEN 'Very Long Delays' \"\n",
    "            +\"WHEN delay >= 120 AND delay < 360 THEN 'Long Delays' \"\n",
    "            +\"WHEN delay >= 60 AND delay < 120 THEN 'Short Delays' \"\n",
    "            +\"WHEN delay > 0 AND delay < 60 THEN 'Very Short Delays' \"\n",
    "            +\"ELSE 'Early' END AS flight_delays\"))\n",
    ".orderBy(asc(\"origin\"),desc(\"delay\"))\n",
    ".show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
